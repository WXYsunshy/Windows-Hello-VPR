
<html xmlns:o="urn:schemas-microsoft-com:office:office"xmlns:w="urn:schemas-microsoft-com:office:word"xmlns="http://www.w3.org/TR/REC-html40">
<body>
    <p>    常熟理工学院毕业设计(论文)</p><p>    PAGE32/NUMPAGES49</p><p>    本科毕业设计(论文)</p><p>    后期修改</p><p>    题目基于声纹识别的门禁应用</p><p>    学院</p><p>    年级专业</p><p>    班级学号</p><p>    姓名</p><p>    校内导师职称</p><p>    校外导师职称</p><p>    常熟理工学院本科毕业设计(论文)诚信承诺书</p><p>    <span style='color:red;'>本人郑重声明:所呈交的本科毕业设计(论文),是本人在导师的指导下,独立进行研究工作所取得的成果。</span>除文中已经注明引用的内容外<span style='color:red;'>,本论文不含任何其他个人或集体已经发表或撰写过的作品成果。对本文的研究做出重要贡献的个人和集体,均已在文中以明确方式标明。本人完全意识到本声明的法律结果由本人承担。</span><br />本人签名:日期:</p><p>    常熟理工学院本科毕业设计(论文)使用授权说明</p><p>    <span style='color:red;'>本人完全了解常熟理工学院有关收集、保留和使用毕业设计(论文)的规定,即:本科生在校期间进行毕业设计(论文)工作的知识产权单位属常熟理工学院。学校有权保留并向国家有关部门或机构送交论文的复印件和电子版,允许毕业设计(论文)被查阅和借阅;学校可以将毕业设计(论文)的全部或部分内容编入有关数据库进行检索,可以采用影印、缩印或扫描等复制手段保存、汇编毕业设计(论文),并且本人电子文档和纸质论文的内容相一致。<br />保密的毕业设计(论文)在解密后遵守此规定。</span></p><p>    本人签名:日期:导师签名:日期:</p><p>    基于声纹识别的门禁应用</p><p>    摘要</p><p>    声纹识别是语音识别中的一种特殊分类,可以通俗得称之为说话人识别。近年来,随着人工智能逐渐进入大众的视线,基于神经网络的身份认证方法得到了进一步的发展。比如人脸识别,虹膜识别以及声纹识别。这些身份认证方法逐渐从理论阶段演化为实际的应用。例如苹果公司在2017年底发布的Face ID -人脸认证识别功能,其改善了传统密码认证跟你指纹认证的方式,无需记住任何密码组合就能够快速解锁iPhone手机。还有例如微软公司在2015年提出的Windows Hello认证应用;其利用微软公司提供的身份信息采集设备将预登陆者的信息录入到系统中,通过嵌入式的算法进行预登陆者的判断,从而实现快速登陆并开始工作。</p><p>    身份认证技术随着科技的发展不断得简化认证步骤,优化认证效率,为信息安全提供着保护,为身份认证增加了便捷。</p><p>    本课题利用高斯混合模型,将从麦克风中采集到的语音信号进行MFCC特诊参数提取,并放入模型中训练,计算出预登陆者与语音库中人员的匹配度,从而实现身份认证功能。<br />关键词:声纹识别人脸识别 Apple 身份认证高斯混合模型</p><p>    Windows hello application based on voice print recognition <br />Abstract</p><p>    Voiceprint recognition is a special category in speech recognition. It can be commonly called speaker recognition. In recent years, with the artificial intelligence gradually entering the public eye, the authentication method based on the neural network has been further developed. For example, face recognition, iris recognition, and voiceprint recognition. These identity authentication methods gradually evolved from the theoretical stage into practical applications. For example, Apple's Face ID - Face Recognition and Recognition feature released at the end of 2017, which improves the way traditional password authentication and your fingerprint authentication can quickly unlock your iPhone without having to remember any combination of passwords. There is also the Windows Hello authentication application, for example, that Microsoft proposed in 2015; it uses the identity information collection device provided by Microsoft to record the information of the pre-landing person into the system, and uses the embedded algorithm to perform the judgment of the pre-landing person, thereby realizing Log in quickly and start working.</p><p>    With the development of technology, identity authentication technology continues to simplify the authentication process, optimize the authentication efficiency, provide protection for information security, and increase convenience for identity authentication.</p><p>    In this project, Gaussian mixture model is used to extract the speech signals collected from the microphone for MFCC diagnosis parameters and put into the model for training. The matching degree between the pre-landing person and the person in the speech library is calculated to realize the identity authentication function.</p><p>    Key Words:Voiceprint recognition Face recognition Apple identity authentication Gaussian mixture model <br />目录</p><p>    TOC \o &quot;1-3&quot;\h \z \u 1.引言8</p><p>    1.1.声纹识别的研究背景与意义8</p><p>    1.2.声纹识别的发展历史与现状9</p><p>    1.3.声纹识别概述10</p><p>    1.3.1.声纹识别的基本原理和系统结构10</p><p>    1.3.2.声纹识别常用的特诊参数10</p><p>    1.3.3.声纹识别常用的建模方法11</p><p>    1.4. Windows Hello概述12</p><p>    1.5.本论文的主要工作12</p><p>    2.开发工具和开发技术14</p><p>    2.1.开发环境14</p><p>    2.2.开发技术14</p><p>    2.2.1.声纹识别技术14</p><p>    2.2.2. Socket传输技术14</p><p>    2.2.3.后台刷新15</p><p>    3.系统设计16</p><p>    3.1.系统配置设计16</p><p>    3.2.详细设计16</p><p>    3.2.1. Windows下桌面应用系统设计17</p><p>    3.2.2. Windows Hello应用设计18</p><p>    3.2.3. Web实时监控日志系统设计18</p><p>    4.语音信号预处理20</p><p>    4.1. Windows下的语音信号采集20</p><p>    4.2.语音数据提取20</p><p>    4.3.分帧与加窗22</p><p>    4.4.预加重23</p><p>    4.5.端点检测24</p><p>    5.语音信号特诊参数提取27</p><p>    5.1.短时帧能量和短时过零率27</p><p>    <span style='color:red;'>5.2. Mel频率倒谱系数(MFCC)27</span></p><p>    6.语音信号训练模型31</p><p>    6.1.高斯混合模型(GMM)概述31</p><p>    6.2.单高斯模型31</p><p>    6.3.高斯混合模型32</p><p>    7.声纹识别方法36</p><p>    8.桌面应用38</p><p>    8.1. MFC界面设计38</p><p>    8.2.实验数据及结果39</p><p>    9. Windows Hello应用41</p><p>    9.1.在Windows登陆界面运行自定义程序41</p><p>    9.2.系统应用流程41</p><p>    10. Web实时监控日志系统43</p><p>    10.1.基于本地的日志系统43</p><p>    10.2.基于远程的web日志系统43</p><p>    结语45</p><p>    参考文献46</p><p>    致谢49</p><p>    引言</p><p>    声纹识别的研究背景与意义</p><p>    随着时代的发展,信息技术与网络通信走遍中国的每一个角落,<span style='color:red;'>人们生活方式的改变,生活节奏的逐渐加快,使得身份验证的数字化、</span>快捷化显得越来越重要。传统的以密码为基础的身份验证技术开始逐渐出现弊端,已经无法再满足现在身份认证中安全性和实效性的要求。然而随着信息科学的快速发展,<span style='color:red;'>近几年人工智能的火热,近年来逐渐发展起来的生物认证技术正成为一种更加便捷、更加安全,更加隐形化的信息安全技术开始逐渐被人</span>们熟知和使用。</p><p>    语言是人类所具有的天然属性之一,<span style='color:red;'>是人类相互通信获取信息的最方便快捷的手段之一,每个人说话都具有各自的生物特征,比如,发音器官的先天性生理差异,后天形成的个人发音习惯等行为差异,因此两个人语音是不可能完全相同的;同时,声纹识别对硬件设备的成本要求不高,对声音的采集只需要一台麦克风就可以完成,在对语音数据的处理阶段,包括噪声处理,特征提取,</span>模式匹配等也可以在一定级别的处理芯片上也可完成处理。<span style='color:red;'>所以搭载在应用设备上通过分析说话人语音的方法来对说话人进行识别就成为了可能,这就是声纹识别。</span><br />声纹识别相比其他生物特征识别相比,使用声纹识别具有如下优势</p><p>    声纹识别能够在用户不知不觉中就能够做完身份验证,<span style='color:red;'>自然得获取说话人的语音,不会涉及到隐私问题,容易被使用者接受。</span></p><p>    <span style='color:red;'>认证方式简单,只需要用户提供足够的录音数据即可,不用像指纹或虹膜识别技术需要将人体器官贴近信</span>息采集仪器。</p><p>    实现成本非常低廉,相比于各<span style='color:red;'>种指纹或虹膜认证技术需要单独购买特殊昂贵的扫描仪器设备,声纹识别只需要简单的语音输入设备,</span>例如一台电脑就可以实现从采集到识别结果的所有过程。</p><p>    在远距离的身份识别中。声纹识别更快捷,通过电话或手机也可实现远距离身份确认。<br />由于声纹识别具有以上优势,声纹识别的前景可以从以下几个领域概述:</p><p>    <span style='color:red;'>随着计算机的发展,如果将语音作为一种交互手段在某种情况下取代键盘和鼠标,通过语音命令来控制机器运算与</span>显示,解放人的双手,人与机器之间的交流也会越来越自然、流畅。</p><p>    <span style='color:red;'>网络购物已经深入人们的日常生活,网上付款时人们很大程度上依赖于密码或二维码,但是随着各种不同场合的频繁使用,网络安全的隐患越来越明显,如果将声纹识别的概念应用到网络安全中,每次验证系统会随机提供提示文本,能够更有效防止复制和剽窃。<br />声纹识别的发展历史与现状</span></p><p>    上个世纪30年代,伴随着信息技术和计算机技术的发展,通过仪器可以实现说话人信息的识别。<span style='color:red;'>&quot;声纹&quot;的概念最早由Bell实验室的L.G.Kesta在研究声谱时提出的。</span>人们的研究中心从听音识别和人耳的听辨实验转移到提取有利的声纹特征上来。</p><p>    <span style='color:red;'>上个世纪40年代至70年代是声纹识别技术的创新阶段,Bell实验室的S.Pruzansky提出了基于模式匹配和概率统计方差分析的说话人识别方法,实现了人耳分辨到自动识别技术的转变</span>,各国的专家学者开始逐渐关注语音处理技术,相继研究提出了倒谱分析技术与线性预测分析技术。</p><p>    <span style='color:red;'>上个世纪70年代至80年代,声纹识别技术的研究重点则在于对声音中个性特征参数的非线性或线性处理技术以及寻找新的更有效的模型匹配方法。例如如今所被人熟知的动态时间规划、神经网络、支持向量机、</span>隐马尔可夫模型等方法。</p><p>    上个世纪90年代至今,各种模式匹配方法逐步成型,高斯混合模型技术作为声纹识别系统较为前沿的方法,收到越来越多的关注,已经成为专家研究的热点。例如国内的讯飞输入法,其快速又准确的识别效率让语音识别技术也逐渐成为街头让人津津乐道的话题。</p><p>    <span style='color:red;'>国内研究声纹识别起步较晚,目前取得较好研究成果的机构中有中科院声学所、中科院自动化所、清华大学、北京大学、中国科学技术大学、</span>上海交通大学等。<span style='color:red;'>近年来在实验室环境下的声纹识别技术已发展成熟。在实际应用环境下的声纹识别技术收到越来越多的研究者关注,尤其是在噪声环境下</span>的声纹识别。所以,抗噪是声纹识别的关键技术问题之一。</p><p>    在相关知识库搜索声纹识别时,早期人们都是使用隐马尔可夫模型来完成模式匹配的工作,而今年来使用高斯混合模型来实现声纹识别的人越来越多,所以,本课题采用MFCC+GMM(Mel倒谱系数+高斯混合模型)的方式来完成。<br />声纹识别概述</p><p>    声纹识别的基本原理和系统结构</p><p>    <span style='color:red;'>声纹识别从目的和判决方式来分类,可以分为两类:说话人确认和说话人辨认。说话人确认用来确定这段话是不是某一个特定的人说的,属于&quot;一对一&quot;问题。说话人辨认用来判断这段话是众多人中其中哪一个人说的,属于&quot;多选一&quot;问题。根据实际情况,不同的工作和任务会采用不同的声纹识别技术。例如网络交易时,</span>需要采用确认(一对一)的技术;刑侦侦察过程中,为了缩小范围,需要采用辨认(一对多)的技术。<br />图片 SEQ 图片\* ARABIC 1声纹识别流程</p><p>    声纹识别作为语音识别中的一部分,<span style='color:red;'>双方存在很大的差异:语音识别通常关注的是说话的人说了些什么,而不关注说话人的声道变化和说话习惯,更不关注说话的人是谁;声纹识别关注的是说话人是谁,而忽略说话人说的是什么话,更注重说话人的说话习惯和声道变化等个性特征。声纹识别的基本原理是利用说话人的语音数据,通过统计学的方法为说话人建立一个能够描述此说话人特征的模型,作为此说话人语音信号特征参数的标准模板,然后和其余待识别者的寄存说话人特征的模型进行对比,如果达到某个标准则认定为</span>某个识别者,从而达到判断说话人身份的目的。(如图片1)<br />声纹识别常用的特诊参数</p><p>    <span style='color:red;'>在说话人识别系统中,原始语音信号预处理后,需要提取其特征参数,即提取一些适合分类的某些信息特征。在声纹识别中样本模型的训练和目标说话人的识别都是依赖于所选的特征参数的特性</span>进行分析比较的。</p><p>    <span style='color:red;'>语音信号的特征参数从各个方面体现了说话人的个性、方言和语义特性。但是由于说话内容的语义特征、说话人的情绪波动以及外界环境的干扰,到现在为止还没有找到在各种情况下都相对稳健的特征参数。所以在声纹识别系统中,存在语音信号的易变形、训练样本数量的不确定性、外界噪声信号的干扰性等问题,声纹识别系统的特征参数提取方法需要业内人士进一步改良与探索。声纹识别的特征参数基本上可以分为三类:</span></p><p>    线性预测系数及其派生系数。<span style='color:red;'>例如:线性预测系数(LPC)、线性预测倒谱系数(LPCC)、</span>及其组合参数。</p><p>    <span style='color:red;'>由语音频谱直接导出的参数。例如:共振峰、梅尔频率倒谱系数(MFCC)、感知线性预测系数(PLP)。</span></p><p>    混合参数。混合参数是由上述不同的特征参数通过某种合理分析所组成的特征矢量。</p><p>    <span style='color:red;'>不同的特征参数对声纹识别系统的识别率影响不同,决定着系统的性能。一个稳定成熟的特征参数不但可以使声纹识别系统的识别率有所提高,而且可以使声纹识别系</span>统的鲁棒性和稳定性有所增强。<br />声纹识别常用的建模方法</p><p>    <span style='color:red;'>在声纹识别系统中,当特征参数提取后,要用合适的模型来表征这些特征参数,使得模型能够代表语音信号的特征。因此,模型的选择应从语音信号的类型、</span>期望的性能、计算量及存储量等方面考虑。目前主要的方法有:<br />概率统计方法</p><p>    <span style='color:red;'>语音信号在短时间内是相对稳定的,通过对这些稳定的特性如基音、共振峰频率等进行数学分析,从而选用概率密度函数和均值、方差等相关统计量对这些特征进行分类判决。概率统计建立的模型是开率了语音信号</span>的统计特性采用某种<span style='color:red;'>概率密度函数的一组参数作为语音模型。概率统计建立的模型通常会从各个方面体现出语音信号的统计信息。本课题采用的方</span>法高斯混合模型就属于概率统计方法。<br />动态时间规划方法(DTW)</p><p>    <span style='color:red;'>说话人的语音信号不但具有稳定性,而且还具有时变性。将识别模型与参考模型进行时间对比,根据一定的距离测量得出两个模型间的相似程度。<br /></span>矢量量化方法(VQ)</p><p>    <span style='color:red;'>该方法是把所有人的特有文本编写成码本,在识别的过程中,根据此码本对测试文本编码,并把判断标准定位量化产生的失真度。</span><br />支持向量机方法(SVM)</p><p>    <span style='color:red;'>支持向量机方法是近年来提出的一种新型的机器学习方法,已广泛应用在指纹识别、人脸识别等模式识别的研究上。SVM是在统计学习理论的基础上建立起来的一种模型,该模型能够较好地解决小样本学习问题。<br />融合方法</span></p><p>    <span style='color:red;'>融合方法是把以上分类方法与不同参数进行组合,这样可以使系统的性能有所提升。目前常用的有识别方法组合以及识别方式的结合。</span><br />Windows Hello概述</p><p>    <span style='color:red;'>Windows Hello是一种生物特征授权方式,用户可以轻松实时访问自己的Windows设备且不用担心因为不设置密码而被人窃</span>取信息。</p><p>    <span style='color:red;'>Windows Hello 通过使用用户的脸部、虹膜或指纹等生物特征来解锁设备,这种技术比传统密码更加安全和快捷。用户就是可以解锁Windows、应用、数据甚至网站和服务的密钥,而不是使用容易被忘记、被破解或随手写下的一串随机排列的字母或数字。相比使用可被共享的密码,</span>Windows Hello 可以帮助用户在不使用、<span style='color:red;'>用密码的前提下直接安全地为应用、网站和网络授权。这样,用户的个人电脑与服务器上就不会存储任何密码,不给黑客可乘之机。</span></p><p>    对于相对外行的使用者来说,Windows Hello 就是一个智能身份认证系统。举例来说,如果用户站在 Windows 设备面前,用户只需要露一下脸,动动手指,它会自动完成识别与身份验证,为你想要的服务进行授权。<br />本论文的主要工作</p><p>    <span style='color:red;'>第一章,介绍了声纹识别的研究背景与意义,阐述了声纹识别的发展历史与现状,介绍了声纹识别的基本原理和本课题的实验流程,常用的特征参数、</span>模式匹配的方法。</p><p>    第二章,介绍了项目的开发环境跟重要的开发技术。其中,简要介绍了本文中声纹识别的两种方式。<br />第三章,介绍了系统的部署配置跟各应用的详细设计结构。</p><p>    第四章,介绍了Windows下如何进行录音,如何将语音文件转化成需要处理的信号数据。<span style='color:red;'>还有对语音信号进行参数提取前的准备工作:分帧、加窗、</span>预加重、端点检测。</p><p>    第五章,介绍了如何提取本文中我们所需要的特征参数;为端点检测所提供的短时过零率与短时帧能量。为建立高斯混合模型所提供的Mel频率倒谱系数。</p><p>    第六章,介绍了如何实现并建立高斯混合模型,如何对高斯混合模型进行参数的估计,及训练参数的。<br />第七章,介绍了如何对结合训练数据,进行说话人的判断。</p><p>    第八章,介绍了如何使用桌面的准备性应用。</p><p>    第九章,介绍了如何使用实际的验证应用。</p><p>    第十章,介绍了如何使用web日志监控系统。</p><p>    开发工具和开发技术</p><p>    开发环境</p><p>    <span style='color:red;'>操作系统:Windows 10 Professional 1709</span></p><p>    <span style='color:red;'>集成开发环境:Visual Studio 2010 Professionnal</span></p><p>    集成开发环境:IntelliJ IDEA 2017.3 Ultimate</p><p>    JDK版本:Java SE Development Kit 8.0.144<br />Web服务器:Apache Tomcat Server 8.36</p><br /><p>    数据库服务器:Mysql 5.6</p><p>    开发技术</p><p>    声纹识别技术</p><p>    本课题使用高斯混合模型建模比较的方法实现声纹识别的关键技术。该系统现有两种方法判定识别结果。</p><p>    1 x N方式:获取用户输入的语音信号,将语音信号处理后放入每个库存人员的语音高斯混合模型中,计算出匹配值,统计出最大的匹配值,该匹配值所对应的人员即是对应的识别结果人员。</p><p>    1 x 1方式:先将标准登陆用户的语音放入标准登陆用户的模型中,计算出概率绝对值,将此数值作为标准值,为其创建高门限和低门限。获取用户输入的语音信号,将语音信号处理后放入标准登陆用户的模型中,计算出对象贬值,如果新贬值在高门限与低门限范围内,则确定其为目标用户。</p><p>    两者的差异在于第一种方式是对象用户与库用户组的比较,表象为一对多,第二种方式为对象用户与标准登陆用户的比较,表象为一对一。适用范围不一样,第一种方式的识别结果为某人,第二种方式的识别结果为是与否。<br />Socket传输技术</p><p>    <span style='color:red;'>Socket又称&quot;套接字&quot;,应用程序通常通过&quot;套接字&quot;向网络发出请求或者应答网络请求。建立网络通信连接至少要一对端口号。Socket本质是编程接口(API),对TCP/IP的封装,TCP/IP也要提供可供程序员做网络开发所用的接口,这就是Socket编程接口;</span></p><p>    利用Socket可以在不同的机器、不同的平台间可靠地传递消息。本课题利用Socket在Windows客户端中将识别的数据集、识别的结果、识别的流程日志和识别的对象语音发送给服务器。从而实现记录日志,监控系统,排除系统异常情况的功能。</p><p>    图片 SEQ 图片\* ARABIC 2 Socket传输数据集流程<br />后台刷新</p><p>    本课题存在的两个部分,Windows客户端与web实时日志监控系统,Windows客户端将识别的结果发送web实时日志监控系统时,日志管理系统后台需要将信息实时的反映在Web前端界面当中。这需要客户端浏览器与Web服务器后台实时连接通信,当Web服务器后台接收到来自Windows客户端发送过来的数据时,从Web服务器后台发送群体通知消息给每个Web客户端浏览器进行实时刷新。这就需要使用WebSocket让Web客户端与Web服务器实时连接。原理同Socket传输技术。<br />系统设计</p><p>    图片 SEQ 图片\* ARABIC 3系统部署配置图</p><p>    系统配置设计</p><p>    本课题的部署配置如图片3所示,本课题分为三大部分:桌面应用、Window Hello应用、web实时日志系统。</p><p>    桌面应用:桌面应用用于测试用户设备当前是否存在合适的录音设备,并录下标准用户的语音,计算好声纹信息文件提供给后期识别认证时使用。</p><p>    Windows Hello应用:Windows Hello应用通过Windows的登陆模式,模拟门禁系统开放与闭合的情况。</p><p>    Web实时日志系统:Web实时日志系统用于监控当前认证设备的使用情况,防止错误识别情况的发生。</p><p>    如图3:桌面应用接受用户输入的语音进行计算,生产个人声音信息配置文件,Windows Hello应用获取到标准用户的信息文件与陌生用户的语音生产的信息配置文件数据信息进行对比,从而判断是否该登陆至目标系统。同时,Windows Hello应用与web实时日志系统进行通信,发送认证与匹配信息实时反馈给标准用户。<br />详细设计</p><p>    Windows下桌面应用系统设计</p><p>    模块分类函数文件功能意义LogLogSystem日志系统的控制MessageQueue消息队列的数据结构ReadConfig配置信息的读取SocketClient消息的发送与结构VPRWavFile_Struct语音文件结构WavFile_Initial语音文件初始化Model_GMM运算模型调用Model_KMeans运算模型调用WavData_CharaParameter语音参数获取WavData_SupportFunction共通取得UICChineseCode编码形式变换Shockwaveflashflash驱动Voiceprint RecognitionDlg Response共通取得Voiceprint RecognitionDlg界面函数WaveRecorder录音操作表格 SEQ 表格\* ARABIC 1应用系统模块意义<br />桌面应用系统使用MFC来开发,相关控件和意义可见第八章。</p><p>    图片 SEQ 图片\* ARABIC 4 Windows Hello应用流程<br />Windows Hello应用设计</p><p>    Web实时监控日志系统设计</p><p>    页面名页面功能login,jsp登陆页面index.jsp动态页面table_complete详细数据页面form_validate批量删除页面表格 SEQ 表格\* ARABIC 2页面列表</p><p>    图片 SEQ 图片\* ARABIC 6 web日志系统数据库结构</p><p>    图片 SEQ 图片\* ARABIC 5 web日志系统包图</p><p>    Web系统使用struts1.3的框架,功能只有查看与删除用。包图如图4。<br />语音信号预处理</p><p>    Windows下的语音信号采集</p><p>    在Windows下可以使用系统自带的API来完成录音操作;使用系统自带的API有两种选择方式,一种是Windows Multimedia API(MMAPI),这种方式是利用WAV录音固定的格式,先设置好音频测试设备的硬件参数,在开辟一个缓冲区,由录音设备按照设置的参数定次数定位长向缓冲区写入录音数据,再由用户定时读取缓冲区的数据,最后将读取的数据存入文件;还有一种是Media Control Interface(MCI),使用这种方式,用户可以简单的使用字符串命令实现录音和放音。本课题中采用MMAPI的方法来获取语音文件。</p><p>    用MMAPI可以实时获得音频数据,MMAPI可以把音频缓冲起来并逐块发送给使用者,这种固定大小的音频裸流数据简称为AudioFrame。当用户预备开始录音时,MMAPI以一种格式打开波形输入设备,发送设备开启消息给回调函数并准备缓冲区,将缓冲区添加到设备,告诉录音设备开始录音。当使用者需要结束录音时,MMAPI告知设备录音结束并发送消息给回调函数处理最后的数据,然后释放缓冲区,最后关闭设备。<br />语音数据提取</p><p>    每一个语音文件(此处专指wav格式)都必定有四个模块(如图2),它们分别为RIFF块、格式块、附加块、数据块,其中RIFF、格式块和附加块的总长度必定是24或26字节,数据块长度不定。RIFF块有如下内容:标识符、文件长度、WAV标志;格式块有如下内容:标识符、格式块长度、格式类别、声道数、采样频率、数据传送速率、样本字节数、样本位数、附加信息,其中附加信息的有无是通过格式块长度来确定的,如果格式块长度为24则附加信息不存在,如果格式块长度为26则存在附加信息;附加块有如下内容:标识符、块长度、补丁哈希值;数据块有如下内容:标识符、数据长度、数据内容。我们在这里主要要用到数据传送速率、样本字节数、样本位数、数据长度跟数据五个图片 SEQ 图片\* ARABIC 7 WAV文件数据结构<br />部分的内容。</p><p>    首先按照文件格式读取文件中我们所需要的内容,读出的数据是以字节的方式存放的,此时的数据并不一定是语音处理的数据,我们需要根据采样位数合并字节,重新换算成语音信号的数据。此处我们实验的数据都是采样位数为16bit的,下面我们就说明以16bit的数据对原字节进行变换的算法:</p><p>    采样位数为16bit,也就是说其由两个单字节的数据组成,这个两个字节分为高字节数据与低字节数据。</p><p>    如果高字节的数据大于0,则判断低字节的数据,如果低字节的数据大于等于0,则新生成的数为高字节的数乘256加上低字节的数,;如果低字节的数小于0,则新生成的数为高字节的数乘256加上那个低字节的数的绝对值加上128,;</p><p>    如果高字节的数据小于0,则判断低字节的数据,如果低字节的数据大于0,则新生成的数为高字节的数的绝对值乘256加上低字节的数的负数,;如果低字节的数小于等于0,则新生成的数为高字节的数的绝对值乘256加上低字节的数的绝对值加上128的负数,;<br />注:A表示高字节数,B表示低字节数,C表示生成的数</p><p>    此时的数据就是语音信号可参与转换的数,其数值的范围此时的数据已经可以参与运算了,但是从实验的角度上,相对过大的数据将会给计算机带来相对较大的负荷,所以此时我们对数值进行&quot;归一化&quot;,将每个数据除以,使得最后的数据范围在-1~1之间。<br />分帧与加窗</p><p>    图片 SEQ 图片\* ARABIC 8宏观分帧示意图</p><p>    语音信号是随时间而变化的,<span style='color:red;'>是一个非平稳状态变化过程,但是在短时间范围内(一般在10-30ms内),其某些特性基本保持不变,即在短时内成相对稳定状态,</span>在学术上这被称之为语音信号的短时平稳性。</p><p>    <span style='color:red;'>任何语音信号的分析和处理必须建立在&quot;短时&quot;的基础上,所以在处理时需要进行分帧处理。分帧是通过可移动的有限长度窗函数进行加权的方法实现的。如图三示意图,</span>图中为语音信号分了两个窗,窗一与窗二,窗一的开始与窗二的开始被称为窗移,若将此图放大若干倍,窗与窗之间数值的变化不大,然而却能够体现语音信号的特征。如图九,就是放大后的图。</p><p>    分帧通常每帧取10~40ms的数据,其中人们常使用25ms作为标准配置,但考虑到后续工作需要对数据进行快速傅里叶变换,当中需要每帧的数据个数为2n,所以,本课题采用的帧长为256、帧移为125。我们通常使用汉明窗作为加窗函数,汉明窗中的数据能够为傅里叶变换提供便利减少数据量,汉明窗函数:图片 SEQ 图片\* ARABIC 9微观分帧示意图<br />(2-1)</p><p>    <span style='color:red;'>其中n表示了当前数据在窗中处于第n个数据,N表示汉明窗的窗长度。</span></p><p>    预加重</p><p>    <span style='color:red;'>研究表明,语音信号的平均功率谱是受到声门激励与口鼻辐射的影响,高频率约在800Hz以上按照6dB/倍频程跌落,导致语音信号低频段能量大,高频段信号能量明显小。而鉴频器输出噪声的功率谱密度则随频率的平方而增加(低频噪声大,高频噪声小),造成信号的低频信噪比很大,而高频信噪比明显不足。从而导致高频传输衰弱,使高频传输困难。</span></p><p>    <span style='color:red;'>因此对语音信号进行预加重,把信号的高频部分进行加重,去除口唇辐射的影响,增加语音的高频分辨率,提高信噪比,改善信号的传输质量。</span></p><p>    预加重使用具有6dB/倍频程的提升高频特性的预加重数字滤波器来实现,它一般是一阶的数字滤波器:<br />Hz=1-&mu;z-1(2-2)</p><p>    其中&mu;为预加重系数,<span style='color:red;'>在相关研究文献实验中通常取0.9,1.0。经过预加重处理后的结果为:<br />yn=xn-&mu;xn-1(2-3)</span></p><p>    端点检测</p><p>    <span style='color:red;'>端点检测是声纹识别中初始化阶段的主要进程,端点检测是从一段语音中判断出语音的前后两个端点。声纹识别系统中使用端点检测,一方面可以减少数据量,节约不必要的时间,另一方面可以减少噪声信号的干扰,使声纹识别更准确。</span></p><p>    在语音处理的过程中,尤<span style='color:red;'>其是当针对孤立多个单词进行识别的情况下,正确的判断词语的起末端点为模型匹配和提升识别率起着不可替代的作用,既可以将信号处理时间削弱至最小,又可以清理掉无声段的噪声影响,最终提高系统的识别性能。在一定程度上端点检测的准确度直接影响着整个语音处理系统的性能。</span></p><p>    双门限端点检测法是音频信号处理当中常用的检测手段,其需要从语音信号中提取出时域范围内的两个特征参数(计算方法见第五章:语音信号特<span style='color:red;'>征参数提取):短时过零率和短时帧能量。双门限端点检测法其结合了短时过零率和短时能量的优点,因此对语音信号的起点和判决更加有效。(实验证明双门限端点检测法只在信噪比较</span>高的情况下具有较高的鲁棒性)</p><p>    <span style='color:red;'>双门限法就是在检测的过程中为短时帧能量和短时过零率均设置两个门限,一个高门限和一个低门限,</span>低门限往往对信号的变化反应比较敏感,而当信号达到一定强度才能超过高门限。具体做法如下:</p><p>    计算并获得最大短时能量、最小短时能量、最大短时平均过零率和最小短时平均过零率就是语音信号的波动范围,下面依据上述的四个范围分别为短时帧能量与短时平均过零率设置双门限(分为高门限与低门限),门限的数值将直接影响到最后端点检测判断的结果。在这里,我们先将高门限设置成语音信号频率强度最高范围的1/4,将低门限设置成语音信号最高频率强度范围的1/8。还要设置一个最短语音长度,用于判断是否为爆破音。转到步骤2。</p><p>    图片 SEQ 图片\* ARABIC 10语音状态转换示意图</p><p>    按照窗的个数同时遍历短时帧能量与短时平均过零率,初始状态为静音状态(语音的三种状态,分别为&quot;静音状态&quot;、&quot;过渡状态&quot;、&quot;语音状态&quot;)。(转换图如图5)转到步骤3。</p><p>    此时语音处于静音状态,如果当前帧的短时帧能量高于所设定的短时帧低门限或者当前帧的短时平均过零率高于所设定的短时帧平均低过零率,则标记当前为语音的起始段转到步骤过渡状态。转到步骤4</p><p>    此时语音处于过渡状态,如果当前帧的短时帧能量小于所设定的短时帧低门限且当前帧的短时平均过零率小于所设定的短时帧平均低过零率,则状态不变(静音状态)。如果当前帧的短时帧能量高于所设定的短时帧高门限或者当前帧的短时平均过零率高于所设定的短时帧平均高过零率。则标识语音转到步骤语音状态。转到步骤5</p><p>    图片 SEQ 图片\* ARABIC 11一段语音的检测效果</p><p>    此时语音处于语音状态,如果当前帧的短时帧能量小于所设定的短时帧低门限且当前帧的短时平均过零率小于所设定的短时帧平均低过零率切当前的时间长度小于最短时间门限则标识为噪音,否则标识为结束点,然后记录保存下起始点,结束点信息。转到步骤2直至遍历结束。</p><p>    图片 SEQ 图片\* ARABIC 12双门限端点检测法流程<br />双门限端点检测流程图如图十二.</p><p>    语音信号特诊参数提取</p><p>    短时帧能量和短时过零率</p><p>    语音信号的能量不是一直不变的,并且各个音之间的能量存在差异,所以可以由此判断出语音信号的个性特点。</p><p>    <span style='color:red;'>短时过零率是指每帧内语音信号通过横轴的次数。在时域范围下横轴上可以看到连续语音信号的波形。若离散语音信号相邻的采样存在不同的代数符号,将此现象成为发生了过零,因此可以计算过零的次数。</span><br />用En代表第n帧语音信号xm的短时能量:</p><p>    (3-1)</p><p>    用Zn代表第n帧的过零率:</p><p>    (3-2)</p><p>    其中sgn[]为符号函数,即</p><p>    sgn[x]=1,x&ge;00,x&amp;amp;lt;0(3-3)</p><p>    wn为窗函数(见2.3分帧与加窗)。</p><p>    Mel频率倒谱系数(MFCC)</p><p>    图片 SEQ 图片\* ARABIC 13 Mel频率倒谱系数示意图</p><p>    人的听觉系统对声音频率的感知是非线性的,人耳相当于一个滤波器组<span style='color:red;'>,它能让人在各种变异环境下正常分辨声音,其滤波作用在对数频率尺度上进</span><span style='color:yellow;'>行,对1000Hz以下的频率声音的感知呈近似线性关系;而对于1000Hz以上频率声音的感知遵循在对数频率坐标上的近似线性关系,使人耳对低频</span><span style='color:red;'>信号更敏感。</span></p><p>    Mel频率滤波器组就是由此实验得到的,<span style='color:red;'>其用于模拟人耳对不同频率语音的感知。Mel频率倒谱系数是用一个在低频区域交叉重叠的三角形滤波器组-Mel滤波器组对语音信号的能量谱进行滤波。Mel滤波器组在信号的低频区域分布较密,中频区域分布较少,高频区域分布较为稀疏,单个滤波器的带通带宽较大,因此,高频区域的频率分辨率较低,频谱信息较弱,导致信息遗漏。</span></p><p>    图片 SEQ 图片\* ARABIC 14 Mel频率倒谱系数提取过程<br />Mel频率倒谱系数的提取过程如下(见图9):</p><p>    图片 SEQ 图片\* ARABIC 15傅里叶变换原理图</p><p>    将每帧的数据进行快速傅里叶变换(FFT),将数据从时域转换为频域。有些信号在时域上是很难看出什么特征的,<span style='color:red;'>但是如果变换到频域之后,就很容易看出特征了。这就是很多信号分析采用快速傅里叶变换变换的原因。</span></p><p>    另外,快速傅里叶变换可以将一个信号的频谱提取出来,这在频谱分析方面也是经常用的。在此处就是利用快速傅里叶变换将信号的频谱提取出来。</p><p>    <span style='color:red;'>XK=n=0N-1Xn∙e-i2&pi;kn/N 离散傅里叶变换(DFT)(3-4)</span></p><p>    <span style='color:red;'>Xn=1Nk=0N-1Xk∙ei2&pi;kn/N 逆向离散傅里叶变换(IDFT)(3-5)<br /></span>求频谱的平方,得到谱线的能量:</p><p>    Ei ,k=xi,k2(3-6)</p><p>    其中i表示第i帧,k表示第k条谱线</p><p>    将谱线能量通过Mel滤波器组</p><p>    求最大/最小Mel频率,及滤波器的中心间距</p><p>    melFremax=1125∙log1+SampleRate2∙700(3-7)<br />melFremin=1125∙log1+0700(3-8)</p><p>    ∆mel=melFremax-melFremin/filterNum+1(3-9)</p><p>    其中melFremax表示的是最大Mel频率,melFremin表示的是最小Mel频率,SampleRate表示的是信号的采样频率,filterNum表示的是帧的个数。<br />求mel滤波器组中每个滤波器的实际频率位</p><p>    fi=floorN+1∙700∙expmelFremin+∆mel∙i1125-1SimpleRate (3-10)<br />I为当前滤波器 melFremin为最小Mel频率</p><p>    N为帧长∆mel为滤波器的中心间距</p><p>    SimpleRate为采样频率</p><p>    将谱线能量通过滤波器</p><p>    Si ,m=k=0N-1Ei,kHmk,0&le;m&amp;amp;lt;M (3-11)</p><p>    Hmkk-fm-1fm-fm-1fm-1&le;k&le;fmfm+1-kfm+1-fmfm&le;k&le;fm+10其他(3-12)<br />I表示第i帧 m表示第m个滤波器</p><p>    N表示帧长 k表示帧内第k个数据</p><p>    M表示滤波器的总个数</p><p>    求对数</p><p>    meli,m=lnmeli,m (3-13)</p><p>    进行离散余弦变换</p><p>    Ci,n=m=0M-1Si,mcos&pi;nm+0.5M 0&le;n&le;L且0&le;m&amp;amp;lt;M (3-14)<br />其中i为帧数,n为阶数表示第i帧中的第n阶</p><p>    M为第m个滤波器 M为总滤波器的个数</p><p>    Si,m为[i][m]位置上的滤波能量</p><p>    语音信号训练模型</p><p>    高斯混合模型(GMM)概述</p><p>    <span style='color:red;'>在声纹识别系统中,模型的建立至关重要,不同的模型建立方法对识别的性能影响不同。在进行声纹识别时,将输入系统的识别语音特征参数和已有的说话人识别模型进行相似比对分析,然后根据对比分析结果对待识别的说话人身份做出相应的判断。因此,声纹识别模型的建立与特征参数提取同等重要,也是声纹识别的关键之一。传统的建模方法:如动态时间规划、人工神经网络等,这些建模方法计算量较大,训练样本的时间较长,缺乏统计特性。高斯混合模型能较好地描述样本空间的稳步,能够对任意形状的分布进行近似。</span></p><p>    近年来调查发现,说话人<span style='color:red;'>的特征分布并没有严格遵循某一个特定分布,例如高斯分布等;但是几乎所有的分布都能够使用高斯分布的混合加权值来近似接近,从而获得了高斯混合模型。基于高斯混合模型的声纹识别技术的基本理论为针对训练话者集合内的每一个说话人构建属于自己身份特征的概率分布模型,这种概率模型中所设计的参数值是由说话人自身的特征参数分布情况所决定,所以可以用以描述说话人的身份特性。</span></p><p>    <span style='color:red;'>高斯混合模型是单一高斯概率密度函数的延伸,GMM能够平滑地近似任意形状的密度分布。高斯混合模型种类有单高斯模型(SGM)和高斯混合模型(GMM)两类。类似于聚类,根据高斯概率密度函数(PDF)参数不同,每一个高斯模型可以看作一种类别,输入一个样本x,即可通过PDF计算其值,然后通过一个阈值来判断该样本是否属于高斯模型。很明显,SGM适合于仅有两类别问题的划分,而GMM由于具有多个模型,划分更为精细,适用于多类别的划分,可以应用于复杂对象建模。<br />单高斯模型</span></p><br /><p>    <span style='color:red;'>单高斯模型的多维高斯(正态)分布概率密度函数定义如下:</span></p><p>    Nx;&mu;,&sum;=12&pi;&sum;exp-12x-&mu;T&sum;-1x-&mu;(4-1)</p><p>    X是维数为d的样本向量(列向量),&mu;是模型期望,&sum;是模型方差。</p><p>    假设训练样本属于类别C,则上式变为:</p><p>    Nx/C=12&pi;&sum;exp-12x-&mu;T&sum;-1x-&mu;(4-2)</p><p>    <span style='color:red;'>其表示了样本属于C的概率大小。若将任意测试样本xi输入式(4-2),均可以得到一个标量Nx;&mu;,&sum;。然后根据贬值t来确定该样本是否属于该类别。</span>(贬值t的确定:可以为经验值,<span style='color:red;'>也可以由实验确定。另外可以先另t=0.7,以0.05为步长一直减到0.1左右,选择使样本变化最小的哪个贬值作为最终t值)</span></p><p>    <span style='color:red;'>单高斯分布模型的几何意义:单高斯分布模型在二维空间近似于椭圆,在三维空间上近似于椭球,因为在很多场合下,同一类别的样本点并不满足&quot;椭圆&quot;分布的特性。所以才引入了高斯混合模型。<br />高斯混合模型</span></p><p>    图片 SEQ 图片\* ARABIC 16高斯混合模型示意图</p><p>    <span style='color:red;'>高斯混合模型是单一高斯机率密度函数的延伸,由于 GMM 能够平滑地近似任意形状的密度分布,因此近年来常被用在语音、图像识别等方面,</span>得到不错的效果。</p><p>    <span style='color:red;'>例如有一批观察数据X=x1,x2 xn,数据个数为n,在d维空间中的分布不是椭球状,那么就不适合以一个单一的高斯密度函数来描述这些数据点的机率密度函数。此时我们采用一个变通方案,假设每个点均由一个单高斯分布生成(具体参数未知),而这一批数据共由M(明确)个单高斯模型生成,具体某个数据属于哪个单高斯模型未知,且每个单高斯模型在混合模型中占的比例未知,将所有来自不同分布的数据点混在一起,该分布称为高斯混合分布。<br />从数学上讲,我们认为这些数据的概率密度分布函数可以通过加权函数表示:</span></p><p>    Pxi=j=1MajNx;&mu;,&sum; j=1Maj=1(4-3)</p><p>    Nx;&mu;j,&sum;j=12&pi;m&sum;jexp-12x-&mu;jT&sum;j-1x-&mu;j (4-4)</p><p>    aj是权值因子,其中的任意一个单高斯分布Nx;&mu;,&sum;叫做这个模型的一个component,<span style='color:red;'>只要j取得足够大,这个xx Mixture Model就会变得足够复杂,就可以逼近任意连续的概率密度分布。</span></p><p>    <span style='color:red;'>高斯混合模型是一种聚类算法,每个component就是一个聚类中心。即在只有样本点,不知道样本分类的情况下,计算出模型参数x;&mu;,&sum;。其计算方法就是EM算法。<br />用训练好的模型去差别样本所属的分类,</span>分为两个步骤:</p><p>    <span style='color:red;'>随机选择k个component中的一个(被选中的概率是aj)。</span></p><p>    <span style='color:red;'>把样本带入刚选好的component中,判断是否属于这个类别,如果不属于则返回第一步。</span></p><p>    <span style='color:red;'>现在假设我们由N个数据点,并假设他们服从某个分布,现在需要确定里面的一些参数的值。</span>例如:在GMM中,我们就需要确定x;<span style='color:red;'>&mu;,&sum;这些参数,我们的想法是:找到这样的一组参数,它所确定的概率分布生成这些给定的数据点的概率最大,而这个概率的乘积则称为似然函数。<br />i=1NPrxi;&theta;似然函数(4-5)</span></p><p>    <span style='color:red;'>通常单个点的概率很小,连乘之后数据会更小,容易造成浮点数下溢,所以一般取对数,公式(4-5)变成:</span></p><p>    i=1NlogPrxi;&theta;称为log-likelihood function (4-6)<br />高斯混合模型的log-likelihood function为:</p><p>    i=1Nlogk=1kakNxi;&mu;k,&sum;k (4-7)</p><p>    要找到最值的模型参数,使GMM的log-likelihood function的期望最大,使用E-M算法求解。</p><p>    <span style='color:red;'>EM算法的基本思路是:随机初始化一组参数&theta;,根据后验概率PrY|x;&theta;来更新Y的图片 SEQ 图片\* </span>ARABIC 17高斯混合模型训练过程</p><p>    <span style='color:red;'>期望EY,然后用EY代替Y求出新的模型参数&theta;,如此迭代直到&theta;趋于稳定。</span></p><p>    <span style='color:red;'>E-Step:假设模型参数已知的情况下隐含变量Z分别取Z1,Z2的期望,亦即Z分别取Z1,Z2的概率。在GMM中求数据点由各个component生成的概率。<br />ri,k=bkPrZk|xi;a,</span>&mu;,&sum;(4-8)</p><p>    <span style='color:red;'>权值因子bk表示在训练集中数据点属于类别Zk的频率,在GMM中它就是ak。</span></p><p>    ri,k=akNxi|&mu;k,&sum;kj=1kajNxi|&mu;j,&sum;j (4-9)</p><p>    M-Step:用最大<span style='color:red;'>似然的方法求出模型参数,认为ri.k就是数据点xi由component k生成的概率。<br />Nk=j=1Nri,k (4-10)</span></p><p>    &mu;k=1Nkj=1Nri,kxi (4-11)</p><p>    &sum;k=1Nkj=1Nri,kxi-&mu;kxi-&mu;kT (4-12)</p><p>    ak=NkN (4-13)</p><p>    声纹识别方法</p><p>    对于一个声纹识别系统,假设整个系统共有N个说话人,其对应的M阶的高斯混合模型参数分别为:&gamma;1,&gamma;2&gamma;N。在辨识阶段,给定一个待识别的语音样本的特征矢量序列X=x1,x2,,xT,分别定义如下几个函数:P&gamma;n,Px,Px|&gamma;k,P&gamma;k|x。<br />P&gamma;n为第n个人的先验概率</p><p>    Px为所有人的特征矢量集的概率密度</p><p>    Px|&gamma;k为第n个人的特征矢量集的概率密度</p><p>    P&gamma;k|x为后验概<span style='color:red;'>率,表示在特征矢量集为x的条件下,确定说话人为第n个人的概率。<br />则这段语音属于第n个说话人的最大后验概率为:</span></p><p>    P&gamma;n|x=Px|&gamma;nP&gamma;nPx=Px|&gamma;nP&gamma;nm=1NPx|&gamma;nP&gamma;n (5-1)<br />识别结果n*可以由最大后验概率给出,即</p><p>    n*=argmax1&le;n&le;NP&gamma;n|x (5-2)</p><p>    假定该语音信号出自封闭集合,则每个人的先验概率相同,则:</p><p>    P&gamma;n=1N 1&le;n&le;N (5-3)</p><p>    即识别结果等价为:</p><p>    n*=argmax1&le;n&le;NPx|&gamma;n (5-4)</p><p>    为了使计算更加简便,通常采用对数似然函数</p><p>    Lx|&gamma;n=lnPx|&gamma;n (5-5)</p><p>    得到判决准则为:</p><p>    n*=argmax1&le;n&le;Nt=1TlnPxt|&gamma;n (5-6)</p><p>    其表示在N个人中能使t=1TlnPxt|&gamma;n最大的第n个人。</p><p>    其中:</p><p>    Px|&gamma;=i=1M&beta;i12&pi;S&sum;iexp-12x-&mu;iT&sum;i-1x-&mu;i (5-7)<br />&beta;i为加权系数 N为库存人数</p><p>    &mu;i为均值向量 M为SGM的个数</p><p>    &sum;i为协方差矩阵 S为GMM的维数</p><p>    桌面应用</p><p>    MFC界面设计</p><p>    本课题使用MFC进行界面上的设计,对录音API与高斯混合模型训练识别进行整合设计完成了一个完整的带有界面的声纹识别系统。下面介绍一些MFC常用的标准控件。</p><p>    <span style='color:red;'>表格 SEQ 表格\* ARABIC 3使用的Windows标准控件</span></p><p>    控件MFC类描述按钮Cbutton用来展示某种行为的按钮,<span style='color:red;'>以及复选框编辑框Cedit用于键入文本列表ClistCtrl显示文本及其图标列表的窗口组合框CcomboBox编辑框与列表的组合静态文本</span>Cstatic常用语为其他控件提供标签图片 SEQ 图片\* ARABIC 18系统界面设计图<br />界面设计如图13所示。</p><p>    通过录音模块中的录音按钮,可以即时录音,软件会<span style='color:red;'>选择操作系统默认的录音设备开始录音,录音格式wav文件(16bit,16000hz,单声道)。录音前可在&quot;录音人&quot;的编辑框中填写录音人名</span>。如果在录音完毕后录音人编辑框中有文字信息,则将录音人信息写入进文件。<br />在语音文件与模型文件中用户能够看到库中的录音跟已经训练完成的数据。</p><p>    用户可以随机选择语音文件中的某一项进行训练,即将录音人的高斯混合模型参数写入文件存入库中。</p><p>    用户可以随机选择语音文件中的某一项进行识别,即将待识别人与语音库中的人进行人员识别。<br />实验数据及结果</p><p>    实验样本数为5,每个样本中说话人所说的内容皆为&quot;我们需要帮助&quot;。训练每个人的语音到语音库中,每次选择其中个语音样本进行识别,看能否确认这个语音样本是否属于他本人。<br />样本wangzhe 文件大小42144B 帧数165</p><p>    WangzheZhanglifeiZhaozouxiangLiuchangZhaoquanPx|&gamma;-713.795-1056.2-1320.7-1451.75-2773.97样本zhanglifei 文件大小96044B 帧数:380</p><p>    WangzheZhanglifeiZhaozouxiangLiuchangZhaoquanPx|&gamma;-3326.97-2166.06-4949.54-3154.88-8358.6样本zhaozouxiang 文件大小43574B 帧数171</p><p>    WangzheZhanglifeiZhaozouxiangLiuchangZhaoquanPx|&gamma;-1113.54-3443.29-724.993-5008.76-3609.02样本liuchang 文件大小47652B 帧数181</p><p>    WangzheZhanglifeiZhaozouxiangLiuchangZhaoquanPx|&gamma;-1080.08-1085.65-1275.73-640.919-3005.28样本zhaoquan 文件大小45630B 帧数177</p><p>    WangzheZhanglifeiZhaozouxiangLiuchangZhaoquanPx|&gamma;-1069.84-1250.03-1249.39-949.363-2898.08在5个样本中样本1、2、3、4都成功识别,只有样本5识别结果为同是女生的Liuchang。整个系统识别率达到80%。<br />Windows Hello应用</p><p>    Windows Hello是操作系统Windows 10中新提出的一种生物验证方法。它可以通过采集登陆者的数据进行后台验证,从而跳过输入密码的过程。</p><p>    在本课题中,我们采用麦克风来采集登陆者信息,如果验证成功,则将密码组合成键盘消息发送给系统登陆程序(logonUI.exe);如果验证失败,则弹出提示信息。<br />在Windows登陆界面运行自定义程序</p><p>    <span style='color:red;'>在系统中运行&quot;regedit&quot;打开注册表,定位到注册表的HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\WindowsNT\CurrentVersion\Image File Execution Options;</span></p><p>    <span style='color:red;'>在[Image File Execution Options]上点击右键,选择[新建]-[项],将其命名为 utilman.exe;</span></p><p>    <span style='color:red;'>点击[utilman.exe],在右侧空白处单击右键,选择[新建]-[字符串值],命名为[Debugger];</span></p><p>    双击打开Debugger,将其数值数据框中输入要打开程序的路径,如[任务管理器]:C:\Windows\System32\taskmgr.exe;</p><p>    设置完成后,在锁定界面点击&quot;轻松使用&quot;将不会打开菜单,而是启动修改后的程序;从而在Windows登陆界面运行声纹识别程序。<br />系统应用流程</p><p>    在系统进入登陆界面时能够启动该应用。应用启动后会立即启动系统默认的录音设备开始采集说话人的信息。接着应用程序会休眠5500ms,在此段时间之内,录音线程会自动将采集到的信息写入指定的缓冲区内。当结休眠结束,应用调用停止录音操作,录音线程将所有采集到的信息写入文件中供后面使用。(录音文件长度约5s,其中500ms用于启动并设置录音设备用。)</p><p>    获取到录音文件后,应用开始读取文件数据,将数据提取出来进行信号初始化并计算信号的特征参数。然后将库存中的数据提取出来,创建高斯混合模型,将预识别人的特征参数放入库存中每个人的高斯混合模型中,计算最大概率。如果最大概率是预先设置的设备使用者的数据集,那么系统会向LogonUI.exe发送登陆密码的组合消息。否则,则弹出提示。从而实现快速登陆。<br />Web实时监控日志系统</p><p>    为了监控系统的状态,捕获异常性的错误信息,web实时监控日志系统记录了所以程序运行时的状态并上传至服务器。该web实时监控系统分为两个部分:基于本地的日志系统。基于远程的日志系统。<br />基于本地的日志系统</p><p>    图片 SEQ 图片\* ARABIC 19本地日志系统</p><p>    当Windows Hello应用程序执行时,会自动向程序存放的位置中新建名为&quot;logs&quot;的文件夹(如果文件夹不存在),并以当前日期的形式新建文本文件。在程序的执行过程中,关键模块的衔接部分或异常性的信息会标明时间同时写入至文件当中。当用户需要时可以随时打开目录文件夹查看应用的执行过程跟执行情况。<br />基于远程的web日志系统</p><p>    本地日志系统只适用于用户能够访问验证机器的情况。但是远程web日志系统能够让已经获得访问许可的人查看日志信息。如果将验证机器通过内网穿透映射至公网内,即使在千里之外也能够查看信息。图片 SEQ 图片\* ARABIC 20远程日志系统</p><p>    将web日志系统发布到web服务器上,通过连接地址打开网站输入登陆账户跟密码即可访问到日志系统。用户可以查看或删除日志信息,从而实现远程监控系统状态。<br />结语</p><p>    本文研究的内容是基于声纹识别的门禁系统,主要通过MFCC倒谱系数和高斯混合模型GMM来进行说话人信息处理。其中对说话人识别所采用的特征向量进行了筛选与组织,给出了MFCC倒谱系数的具体提取过程和算法。还有高斯混合模型的研究,最终将高斯混合模型与实际应用相结合起来,完成了这样一个Windows Hello的声纹识别系统。</p><p>    起初想到这个题目是从朋友那里听来的&quot;语音签名&quot;这个词汇。原本是准备制作医疗信息系统(因为原先的指导老师做了医疗信息系统公司的高级技术顾问,准备利用现有条件开发产值的高新技术系统),但我个人的意思是将&quot;语音签名&quot;的本质声纹识别结合身边的应用做出一个发展。所以我就想到了Windows Hello这样一个概念。</p><p>    经过一个学期的准备与三个月的制作,浏览了44篇论文,参考了68篇网络技术博客,终于完成了本课题。这个系统最终只是一个实验系统,期待未来能够真正的与微软公司合作,加入声纹识别这样一个认证方式。</p><p>    最后,希望有一天,说话人识别技术能够真正成熟起来,与其他技术结合起来在现实生活中大放异彩。</p><p class='uncheck'>参考文献</p><p class='uncheck'>    </p><p class='uncheck'>    基础框架部分：</p><p class='uncheck'>    [1] 杨胜跃，周宴宇. 语音信号端点检测方法与展望. [J].通信技术, 2005，卷号（07）: 0005-04．</p><p class='uncheck'>    [2] 刘波.基于短时能量和过零率分析的语音端点检测方法研究[R].湖北武汉：武汉理工大学信息工程学院，2004．</p><p class='uncheck'>    [3] 李爱平，党幼云. VQ声纹识别算法和实验. [J].西安工程科技学院学报, 2007，卷号（21）: 0848-04．</p><p class='uncheck'>    [4] 周跃海，童峰. 采用DTW算法和语音增强的嵌入式声纹识别系统. [J].厦门大学学报, 2012，卷号（51）: 0174-05． </p><p class='uncheck'>    [5] 于娴，贺松. 基于GMM模型的声纹识别模式匹配研究. [J].通信技术, 2015，卷号（48）: 0097-05．</p><p class='uncheck'>    [6] 王正创．基于MFCC的声纹识别系统研究[D]．无锡：江南大学，2014．</p><p class='uncheck'>    [7] 鲁晓倩，关胜晓. 基于VQ和GMM的实时声纹识别研究. [J]., 2014，卷号（23）</p><p class='uncheck'>    [8] 赵峰,于洋. 基于VQ和HMM 的双层声纹识别算法. [J].桂林电子科技大学学报, 2017，卷号（37）: 0008-07．</p><p class='uncheck'>    [9] 臧晓笠. 基于基于高斯混合模型GMM的说话人识别方法. [J].科技信息, 2006</p><p class='uncheck'>    [10] 辽宁工业大学.基于高斯混合模型的声纹识别方法及系统[P].CN：102324232 A，2011．</p><p class='uncheck'>    [11] 张超琼，苗夺谦. 基于高斯混合模型的语音性别识别. [J].计算机应用, 2007，卷号（28）: 0360-03．</p><p class='uncheck'>    [12] 茅剑，林奇. 基于声纹识别的嵌入式防盗系统. [J].计算机与现代化, 2009，卷号（11）: 0163-03．</p><p class='uncheck'>    [13] 周雷．基于MFCC的声纹识别的说话人身份确认方法的研究[D]．上海：上海师范大学，2016．</p><p class='uncheck'>    [14] 杨阳，陈永明. 声纹识别及其应用. [J].语音技术, 2007，卷号（02）: 0045-02．</p><p class='uncheck'>    [15] 裴鑫．声纹识别系统关键技术研究[D]．哈尔滨：哈尔滨理工大学，2016．</p><p class='uncheck'>    [16] 朱浩冰，郭东辉. 声纹识别系统原理及其关键技术. [J].网络安全, 2007，卷号（09）．</p><p class='uncheck'>    [17] 古今，郭立. 一种基于感知特征的鲁棒性语音认证算法. [J].中国科学院研究生院学报, 2009，卷号（26）: 474-482．</p><p class='uncheck'>    [18] 古今．语音感知认证的关键技术研究[D]．合肥：中国科学技术大学，2009．</p><p class='uncheck'>    特征参数部分：</p><p class='uncheck'>    [19] 周萍，李晓盼. 混合MFCC特征参数应用于语音情感识别. [J].计算机测量与控制, 2013，卷号（21）: 1996-03．</p><p class='uncheck'>    [20] 郭春霞，裘雪红. 基于MFCC的说话人识别系统. [J].电子科技, 2005，卷号（11）: 11-012．</p><p class='uncheck'>    [21] 韩一，王国胤. 基于MFCC的语音情感识别. [J].重庆邮电大学学报, 2008，卷号（20）: 0597-06．</p><p class='uncheck'>    [22] 丁爱明．基于MFCC和GMM的说话人识别系统研究[D]．南京：河海大学，2006．</p><p class='uncheck'>    [23] 王恩泽，何东健. 基于MFCC和双重GMM的鸟类识别方法. [J].计算机工程与设计, 2014，卷号（35）: 1868-04．</p><p class='uncheck'>    [24] 王萌，王福龙. 基于端点检测和高斯滤波器组的MFCC说话人识别. [J].计算机系统应用, 2016，卷号（25）</p><p class='uncheck'>    [25] 何朝霞，潘平. 说话人识别中改进的MFCC参数提取方法. [J].计算机技术与工程, 2011，卷号（11）</p><p class='uncheck'>    训练模型部分：</p><p class='uncheck'>    [26] 向昌盛. 高斯混合模型心音信号自动识别. [J].南京理工大学学报, 2016，卷号（40）: 0560-06．</p><p class='uncheck'>    [27] 蔡桂林．高斯混合模型用于语音情感识别研究[D]．广西：广西师范大学，2016．</p><p class='uncheck'>    [28] 翟玉杰．基于GMM-SVM说话人识别的信道算法研究[D]．吉林：吉林大学，2015．</p><p class='uncheck'>    [29] 陈银燕．基于HMM和GMM天然地震与人工爆破识别算法研究[D]．广西：广西师范大学，2011．</p><p class='uncheck'>    [30] 张奇，苏鸿根. 基于高斯混合模型的乐器识别方法. [J].计算机工程, 2004，卷号（30）: 0133-02．</p><p class='uncheck'>    [31] 杨澄宇，赵文. 基于高斯混合模型的说话人确认系统. [J].计算机应用, 2001，卷号（21）: 0007-02．</p><p class='uncheck'>    [32] 余清清，李应. 基于高斯混合模型的自然环境声音的识别. [J].计算机工程和应用, 2011，卷号（25）: 152-155．</p><p class='uncheck'>    [33] 任民宏，鲁秋菊. 基于高斯混合模型自适应肤色识别算法. [J].陕西理工学院学报, 2016，卷号（32）: 0053-04．</p><p class='uncheck'>    [34] 许百林．基于矢量量化（VQ）和高斯混合模型（GMM）的说话人识别的研究[D]．南京：东南大学，2005．</p><p class='uncheck'>    [35] 刘恒，吴迪. 运用高斯混合模型识别动物声音情绪. [J].应用天地, 2016，卷号（35）: 520-20．</p><p class='uncheck'>    性别识别部分：</p><p class='uncheck'>    [36] 肖汉光，何为. 基于MFCC和SVM的说话人性别识别. [J].重庆大学学报, 2009，卷号（32）: 0770-05．</p><p class='uncheck'>    [37] 旁程，李晓飞. 基于MFCC与基频特征贡献度识别说话人性别. [J].华中科技大学学报, 2013，卷号（41）: 0108-04．</p><p class='uncheck'>    [38] 高原．基于性别分类的说话人识别研究[D]．徐州：江苏师范大学，2012．</p><p class='uncheck'>     </p><p class='uncheck'>    致谢</p><p class='uncheck'>    请允许我致谢，为这四年一路走来的成长，为我经历和得到的所有。</p><p class='uncheck'>    首先我要感谢带我走进语音信号处理的刘永俊老师，虽然刘老师从来没有对我做出实质性的指导，虽然刘老师常常把我们的成果占为己有，虽然刘老师慢慢变成一个商人而不是一个老师。但我还是得感谢他；我依然记得大二的时候参与的第一个实验室项目，刘老师找了一个划水的项目主持人混了一个校级项目，骗了学校2000块钱。正因为这样，我才能出色得表演我的产品经理天赋。也正因为这样，我才在语音信号中约扎越深。最终在零指导下，单靠查阅资料完成了省级项目。正因为这样，我才知道，原来我竟然有这么强的学习能力。</p><p class='uncheck'>    我还要感谢我的同窗秦立浩，我做语音，他做图像。他其实比我更加适合做研究性的内容，我适合做一个项目经理。虽然他常常幻想担任我的角色，但其实我更喜欢他这样的人才。毕业了，他考研去了，我即将进入公司，我不清楚我的未来是不是还能遇见这样的朋友，但如果再见，我一定让他担任我们公司的研发组组长。</p><p class='uncheck'>    感谢我的指导老师，虽然我在写这篇致谢的时候我才大三，但我知道，未来的你一定是一个认真负责的老师。一定是你，也只有你才能知道我的论文到这么完美的地步。</p><p class='uncheck'>    感谢14软件单招班的所有同学，虽然你们都爱玩游戏，但我相信，未来一定有属于你们的出路。请不要畏惧，向着你们所向往的目标去飞吧，你们是我这24年来的骄傲与辉煌的见证者。</p><p class='uncheck'>    感谢所有教导过我们的老师们，在我心里，你们各有特色，感谢你们的教导，感谢你们！</p><br />
</body>
</html>

